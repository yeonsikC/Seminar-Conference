{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7v8U6s-cUk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "c53a9bea-5734-4b60-92f4-19e3f167f985"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta0 #텐서플로우 가장 최신버젼 ( 2019-07-04 )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/7e/87c4c94686cda7066f52cbca4c344248516490acdd6b258ec6b8a805d956/tensorflow_gpu-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (348.8MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.16.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.33.4)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta0) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (3.1.1)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuGCPXR0meuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67ba970b-6d2b-499f-dca3-c433f485a802"
      },
      "source": [
        "import tensorflow as tf #버젼 확인\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-beta0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-zgheB5m6Bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "08417cc6-88cc-4487-85cd-df327d0ace9d"
      },
      "source": [
        "!nvidia-smi # 리눅스 명령어 \" GPU 할당 확인\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  4 01:32:14 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVhhoCuznFio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "d8d96cc4-12bf-41f1-894e-e27ed38a1efd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyZR_WXInk_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d9c29ac0-f96c-4159-e033-3138fad01b32"
      },
      "source": [
        "!ls '/gdrive/My Drive/Colab Notebooks/datas/keras'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2BA90A35.txt  2BA91A46.txt  2BA93A22.txt  2BA93B13.txt\t2BB9313.txt\n",
            "2BA90A44.txt  2BA91A56.txt  2BA93A24.txt  2BA95L58.txt\t2BB9314.txt\n",
            "2BA91A05.txt  2BA92A37.txt  2BA93A32.txt  2BB9301.txt\t2BH9910.txt\n",
            "2BA91A15.txt  2BA92A47.txt  2BA93A34.txt  2BB9304.txt\t2BH9911.txt\n",
            "2BA91A36.txt  2BA93A20.txt  2BA93A48.txt  2BB9306.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vtiNUnvn3WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from random import shuffle\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from itertools import chain\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEmPmekK0UBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define valid character set\n",
        " ##글자 하나하나에 인덱스 부여\n",
        "  ##유니코드 이용, 쓸 한글들을 define.\n",
        "complete_kor_range = range(0xac00, 0xd7a4)\n",
        "  ##유니코드 이용, 쓸 영어들을 define.\n",
        "complete_eng_range = range(0x0041, 0x007b)\n",
        "#punctuations = '~!@#$%^&*()-_=+{}[];:\\'\"<>,./?'\n",
        "  ##숫자 하나하나에도 인덱스로 부여. 문자로 생각. 숫자가 8이면 붙고 9면 뗄 수도 있다라는 뜻.\n",
        "numbers = '0123456789'\n",
        "\n",
        "#mapping 테이블 생성. 인덱스가 들어오면 그 캐릭터가 무엇인지.\n",
        "idx_to_chr = []\n",
        "##캐릭터가 들어오면 그 인덱스가 무엇인지 하는 dictionary\n",
        "chr_to_idx = {}\n",
        "# The first few indices are reserved\n",
        "## 0번째 인덱스는 패딩. ( 글자가 부족할 때 남는 값을 무엇으로 채울거냐?) 글자가 없으면 0으로 채우겠다.\n",
        "idx_to_chr.append('<PAD>')\n",
        "idx_to_chr.append('<START>')\n",
        "## 다른 나머지 모르는건 unknown 토큰으로 지정. 위에 지정하지 않은 값들은 모르는 값으로 지정.\n",
        "idx_to_chr.append('<UNK>') # unknown\n",
        "\n",
        "# A list mapping indices to words\n",
        "idx_to_chr.extend(numbers)\n",
        "#idx_to_chr.extend(punctuations)\n",
        "for i in chain(complete_kor_range, complete_eng_range):\n",
        "    idx_to_chr.append(chr(i))\n",
        "\n",
        "# A dictionary mapping charactes to integer indices\n",
        "for v, k in enumerate(idx_to_chr):\n",
        "    chr_to_idx[k] = v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imLkbNq501SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce5b6a56-b602-4db8-a3fb-bbcd1d115119"
      },
      "source": [
        "idx_to_chr[0:10]\n",
        "#인덱스 순서대로 캐릭터가 나옴.\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>', '<START>', '<UNK>', '0', '1', '2', '3', '4', '5', '6']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNqt9IT905vB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39fe455c-3cb3-429a-bc24-aa0094c23038"
      },
      "source": [
        "chr_to_idx['가']\n",
        "#'가'라는 글자의 인덱스를 확인."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcRh_dVv2M9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_string(s):\n",
        "    encoded = []\n",
        "    for c in s:\n",
        "        try:\n",
        "            idx = chr_to_idx[c]\n",
        "        except:\n",
        "            idx = chr_to_idx['<UNK>']\n",
        "        encoded.append(idx)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def get_label(s, idx=0):\n",
        "    label = []\n",
        "    while True:\n",
        "        try:\n",
        "            next_ch = s[idx + 1]\n",
        "        except:\n",
        "            # End of sentence\n",
        "            label.append(0)\n",
        "            break\n",
        "        if next_ch == ' ':\n",
        "            label.append(1)\n",
        "            idx += 2\n",
        "        else:\n",
        "            label.append(0)\n",
        "            idx += 1\n",
        "    return label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hyZzk3K2XnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##텍스트 파일 하나에 2GB 넣고. 한번에 돌리기에는 컴퓨터에 무리가 생김.\n",
        "##작은 텍스트 파일 여러개로 불러옴.\n",
        "def build_dataset(filenames, batch_size=64, max_text_len=200):\n",
        "    X_batch = []\n",
        "    y_batch = []\n",
        "    \n",
        "    for p in tqdm(filenames):\n",
        "        # Compiled regex to filter tags\n",
        "        treg = re.compile('<\\w*>|</\\w*>')\n",
        "        # Compiled regex to filter whitespaces\n",
        "        wreg = re.compile(' ')\n",
        "        with open(p, 'r', encoding='utf-8') as f:\n",
        "            # Parse html file\n",
        "            html = f.readlines()\n",
        "            html = ''.join(html)\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            # Use paragraphs only\n",
        "            texts = soup.find_all('p')\n",
        "            texts = [treg.sub('', str(t)).strip() for t in texts]\n",
        "            # Filter zero length input sentences\n",
        "            # and convert to lowercase\n",
        "            texts = [t.lower() for t in texts if t]\n",
        "\n",
        "            # Compute labels\n",
        "            ## get_label : 문장을 가져왔을 때, 그 글자의 다음 칸에 띄어쓰기가 있으면 1, 없으면 0.\n",
        "            labels = [get_label(t) for t in texts]\n",
        "            # Remove whitespaces\n",
        "            texts = [wreg.sub('', str(t)) for t in texts]\n",
        "            texts = [encode_string(t) for t in texts]\n",
        "\n",
        "            X_batch += texts\n",
        "            y_batch += labels\n",
        "    \n",
        "    X_batch = pad_sequences(X_batch, maxlen=max_text_len, \n",
        "                            padding='post', truncating='post',\n",
        "                            value=chr_to_idx['<PAD>'])\n",
        "    y_batch = pad_sequences(y_batch, maxlen=max_text_len, \n",
        "                            padding='post', truncating='post',\n",
        "                            value=chr_to_idx['<PAD>'])\n",
        "    \n",
        "    return (X_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdmSeeDi2cdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "44ea92d6-755c-4db3-af78-399a6d5b5375"
      },
      "source": [
        "##데이터 경로\n",
        "filenames = glob('/gdrive/My Drive/Colab Notebooks/datas/keras/*.txt')\n",
        "shuffle(filenames)\n",
        "\n",
        "train_filenames = filenames[:100]\n",
        "val_filenames = filenames[100:120]\n",
        "#test_filenames = filenames[2000:]\n",
        "\n",
        "print('Total {} files.'.format(len(filenames)))\n",
        "print('Using {} files for training.'.format(len(train_filenames)))\n",
        "print('Using {} files for validation.'.format(len(val_filenames)))\n",
        "#print('Using {} files for test.'.format(len(test_filenames)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 150 files.\n",
            "Using 100 files for training.\n",
            "Using 20 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5OfDTUN3Izx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "07c870ba-f483-4a4a-82a7-2cc05b5ddae2"
      },
      "source": [
        "##텍스트의 길이 지정. \n",
        "max_text_len = 200\n",
        "\n",
        "X_train, y_train = build_dataset(train_filenames, max_text_len=max_text_len)\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "\n",
        "X_val, y_val = build_dataset(val_filenames, max_text_len=max_text_len)\n",
        "print('X_val.shape: ', X_val.shape)\n",
        "print('y_val.shape: ', y_val.shape)\n",
        "\n",
        "#X_test, y_test = build_dataset(test_filenames, max_text_len=max_text_len)\n",
        "#print('X_test.shape: ', X_test.shape)\n",
        "#print('y_test.shape: ', y_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.42it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train.shape:  (106681, 200)\n",
            "y_train.shape:  (106681, 200)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:11<00:00,  1.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_val.shape:  (20794, 200)\n",
            "y_val.shape:  (20794, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP0bqJ2N3MRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "4200cdae-ad5e-4b75-da7e-b0d0ea15244c"
      },
      "source": [
        "x_train[0] ## 0이 없다. : 200글자를 꽉 채워서."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-06d306a09912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m## 0ㅇ이 없다. : 200글자를 꽉 채워서.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm_rBe253heA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "eea74f7a-7f85-435d-8d1d-f165a2ae2fb6"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNH0Lh7T3iNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "b275b09b-7d83-484f-e813-ea59a89a2e4c"
      },
      "source": [
        "##잘 되었는지 확인.\n",
        "idx = 99\n",
        "print('Encoded string')\n",
        "print(X_train[idx])\n",
        "print('\\nEncoded label')\n",
        "print(y_train[idx])\n",
        "\n",
        "print('\\nWhen converted back to string')\n",
        "for i, c in enumerate(X_train[idx]):\n",
        "    print(idx_to_chr[c], end='')\n",
        "    if y_train[idx][i] == 1:\n",
        "        print(' ', end='')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded string\n",
            "[ 5445   209 10345  7437  6649   409  6989  3765  2141    11    11    41\n",
            "  7013  5688  7069  6733   573 10821  3177   377  5438  2089  6497 10821\n",
            "  6621  6649 10646    42  7013  7041  3473  5438  4305  5354  7049   378\n",
            "  7182  2302  6993   573  7097 10597  2001  3178 10597   237  7061  1777\n",
            "     2 10629  2337  6481  7041  1697    11    11    41   525  7069  3177\n",
            "   377  5438  2089  6497 10821  3465  1781     5  8469  3545  6621  7050\n",
            "  6593  1221  1777     2  5869  6838  8833  2281  3465  7293 10905 10597\n",
            "  2300  6649   409  6993  7069  2022  7045  5866  7090  8805  6621  9666\n",
            "   265  5865  9393  3713  8961 10485  9533  3765  1749  9533  6621  7045\n",
            "  5866  2089  5688  7069  6733  7045  7182  5305 10618  7041 10345  5865\n",
            "  2089  1777     2  1889  7069  5445 10601  1217  6838  6993  7293  5305\n",
            " 10597  3121  3713   258 10618 10821  5809  9925  8961 10485  9533  6621\n",
            "  6653   189  2089  7069  3289  3465  8267  6481 11216  7293 10905     2\n",
            "  2957  6985  3177  2289  6593    17  1777     2     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "\n",
            "Encoded label\n",
            "[0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1\n",
            " 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "When converted back to string\n",
            "세계표준여권은 모두 88 개의 숫자와 기호로 구성된 암호에 여행객의 이름 성별 생일 국적 등을 기재하도록 하고 있다<UNK> 핸디아이는 88 개 글자로 구성된 암호를 단 2 초만에 읽어낸다<UNK> 신용카드를 조회하듯 여권을 자동인식장치에 통과시키면 컴퓨터모니터에 인식된 숫자와 인적사항이 표시된다<UNK> 더 자세한 내용을 조사하려면 공항 호스트컴퓨터에 연결된 자료를 찾아 `조회<UNK>란으로 들어간다<UNK><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCTpz6in3p7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##딥러닝이 항상 깊게 가는것은 아니다. 하나의 인풋이 여러개로 들어감 : wide하게 간다.\n",
        "def conv_block(x, filter_nums, filter_sizes):\n",
        "    \"\"\"A convolution block\"\"\"\n",
        "    conv_blocks = []\n",
        "##필터 넘버와 사이즈를 받음.\n",
        "    for fn, fs in zip(filter_nums, filter_sizes):\n",
        "        conv = layers.Conv1D(filters=fn,\n",
        "                             kernel_size=fs,\n",
        "                             padding='same',\n",
        "                             activation='relu',\n",
        "                             strides=1)(x)\n",
        "        #conv = layers.GlobalMaxPooling1D()(conv)\n",
        "        conv_blocks.append(conv)\n",
        "\n",
        "    return conv_blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg45ggms3vWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "376a2edf-a2e4-4b9e-a94b-e9e723c85d6e"
      },
      "source": [
        "USE_MULTI_GPU = True ##COLAB에서는 FALSE해도댐\n",
        "\n",
        "def Model():\n",
        "    inputs = layers.Input(shape=(max_text_len,)) ##max 200이므로 200개만 가져오겠다.\n",
        "    ##임베딩을 하겠다 : 아래 코드 추가.\n",
        "    ##200글자를 가져오고\n",
        "    ##100 : 100차원으로 맵핑. - 하나의 캐릭터가 100차원으로 구현. - 모델의 수정해보겠다 : 이 값을 바꿔봐라.\n",
        "    ##input_length 수정 : 들여올 단어 개수를 수정\n",
        "    ##최종적으로 200 * 100 행렬\n",
        "    x = layers.Embedding(len(idx_to_chr), 100, input_length=max_text_len)(inputs)\n",
        "    ##256개에 4그램. 256개에 6그램 ```\n",
        "    blocks = conv_block(x, filter_nums=(256, 256, 256, 256, 256), \n",
        "                           filter_sizes=(4, 6, 8, 10, 12))\n",
        "    x = layers.Concatenate()(blocks)\n",
        "    ##LSTM 두번 거침.\n",
        "    x = layers.LSTM(100, \n",
        "                    dropout=0.3,\n",
        "                    #recurrent_dropout=0.3,\n",
        "                    return_sequences=True)(x)\n",
        "    x = layers.LSTM(50,\n",
        "                    dropout=0.1,\n",
        "                    #recurrent_dropout=0.1,\n",
        "                    return_sequences=True)(x)\n",
        "    ##TD : Dense 값을 (똑같의 오퍼레이션을) 각각의 하나의 엘리멘테이션에 적용해주겠다. : 사이즈(크기를) 조절할 수 있음.\n",
        "    x = layers.TimeDistributed(layers.Dense(300, activation='relu'))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(150, activation='relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)\n",
        "    ##마지막 라벨이 200차원으로 맞춰짐.\n",
        "    x = layers.Reshape((200,))(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "\n",
        "    return model\n",
        "\n",
        "if USE_MULTI_GPU:\n",
        "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "    #mirrored_strategy = tf.distribute.get_strategy()\n",
        "    with mirrored_strategy.scope():\n",
        "        model = Model()\n",
        "        ## loss optimizer 쓰기 편함 그냥 적기만 하면 됨.\n",
        "        ## accuracy를 많이 쓰면 너무 느려짐. 아래 주석을 하나씩 추가하면 더 알 수 있음.\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "                               #tf.metrics.Precision(),\n",
        "                               #tf.metrics.Recall(),\n",
        "                               #tf.metrics.AUC()])\n",
        "\n",
        "        model.summary()\n",
        "else:\n",
        "    model = Model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "                           #tf.metrics.Precision(),\n",
        "                           #tf.metrics.Recall(),\n",
        "                           #tf.metrics.AUC()])\n",
        "    model.summary()\n",
        "    \n",
        "    ##최종적으로 200차원의 값으로 나왔다."
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 200, 100)     1124300     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 200, 256)     102656      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 200, 256)     153856      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 200, 256)     205056      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 200, 256)     256256      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 200, 256)     307456      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 200, 1280)    0           conv1d[0][0]                     \n",
            "                                                                 conv1d_1[0][0]                   \n",
            "                                                                 conv1d_2[0][0]                   \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "                                                                 conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 200, 100)     552400      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 200, 50)      30200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 200, 300)     15300       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 300)     0           time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 200, 150)     45150       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 200, 1)       151         time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 200)          0           time_distributed_2[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 2,792,781\n",
            "Trainable params: 2,792,781\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627NBR7f3x7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "af469fed-1026-4882-f660-17f43907618b"
      },
      "source": [
        "MODEL_SAVE_DIR_PATH = './models'\n",
        "if not os.path.exists(MODEL_SAVE_DIR_PATH):\n",
        "    os.makedir(MODEL_SAVE_DIR_PATH)\n",
        "\n",
        "model_path = os.path.join(MODEL_SAVE_DIR_PATH, '{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}.hdf5')\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c6b8728cb90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMODEL_SAVE_DIR_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./models'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_DIR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_DIR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'makedir'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSzjeX1R5e7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute global batch size using number of replicas.\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "global_batch_size = (BATCH_SIZE_PER_REPLICA *\n",
        "                     mirrored_strategy.num_replicas_in_sync)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(1024)\n",
        "train_dataset = train_dataset.batch(global_batch_size)\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "valid_dataset = valid_dataset.batch(global_batch_size)\n",
        "valid_dataset = valid_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zBnuJ9z6QgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "istory = model.fit(train_dataset,\n",
        "                    epochs=3,\n",
        "                    validation_data=valid_dataset,\n",
        "                    steps_per_epoch=len(y_train)//global_batch_size,\n",
        "                    validation_steps=len(y_val)//global_batch_size,\n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzV_diBn6QoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=3,\n",
        "                    batch_size=1024,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wLtht2x6Ql3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDy6M8st6QjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot([1, 2, 3], [0.0331, 0.0256, 0.0223], 'bx-', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot([1, 2, 3], [0.1639, 0.0596, 0.0529], 'ro-', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLdXzwaU6QeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}